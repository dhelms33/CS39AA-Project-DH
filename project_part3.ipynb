{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 3\n",
    "\n",
    "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/dereckhelms/cs39aa-project-part-2)\n",
    "\n",
    "Colab link is a work in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creation of Feed-Forward Model\n",
    "Although I do not believe a feed-forward model is the most appropriate for this set of structured data, I want to construct one to see how it behaves in relation to another deep learning model. \n",
    "Below are the imports I will use for this section.\n",
    "It is necessary to convert the binary smoker feature to one hot encoding for the model to analyze it without errors. StandardScaler is used to scale the data to a normal distribution and if all the data is not of float type I will receive many errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Desktop\\CS\\CS39AA-Project-DH\\project_part3.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Desktop/CS/CS39AA-Project-DH/project_part3.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Desktop/CS/CS39AA-Project-DH/project_part3.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Desktop/CS/CS39AA-Project-DH/project_part3.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Desktop/CS/CS39AA-Project-DH/project_part3.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Desktop/CS/CS39AA-Project-DH/project_part3.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('insurance.csv')\n",
    "\n",
    "# Extract features and target variable\n",
    "features = df[['age', 'bmi', 'children', 'smoker', 'region']]\n",
    "target = df['charges']\n",
    "\n",
    "# Explicitly create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
    "features = features.copy()\n",
    "\n",
    "# Convert categorical features to one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "features['smoker'] = label_encoder.fit_transform(features['smoker'])\n",
    "features = pd.get_dummies(features, columns=['region'])\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "features[['age', 'bmi', 'children']] = scaler.fit_transform(features[['age', 'bmi', 'children']])\n",
    "\n",
    "# Ensure all data is of numeric type\n",
    "features = features.astype('float32')\n",
    "target = target.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Define the model architecture\n",
    "class InsuranceModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(InsuranceModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # Adjust the number of hidden units as needed\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 1)  # Output is a single number for insurance charge prediction\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create a model instance\n",
    "input_size = X_train_tensor.shape[1]\n",
    "model = InsuranceModel(input_size)\n",
    "\n",
    "# Set up the loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adjust the learning rate as needed\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    predictions = model(X_train_tensor)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print training information\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    test_loss = criterion(test_predictions, y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "\n",
    "# Print some predicted versus actual values\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    sample_indices = np.random.choice(len(X_test_tensor), 5, replace=False)\n",
    "    for i in sample_indices:\n",
    "        prediction = model(X_test_tensor[i])\n",
    "        print(f'Sample {i + 1}: Predicted={prediction.item():.4f}, Actual={y_test_tensor[i].item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already trained the model and obtained predictions\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predictions = model(X_test_tensor)\n",
    "\n",
    "# Convert torch tensors to numpy arrays for visualization\n",
    "y_pred = predictions.numpy()\n",
    "y_actual = y_test_tensor.numpy()\n",
    "\n",
    "# Create separate scatter plots for each feature\n",
    "\n",
    "# Plot for BMI\n",
    "plt.scatter(X_test_tensor[:, 2].numpy(), y_actual, color='red', label='Actual Charges')\n",
    "plt.scatter(X_test_tensor[:, 2].numpy(), y_pred, color='blue', label='Predicted Charges')\n",
    "plt.xlabel(\"BMI\")\n",
    "plt.ylabel(\"Charges\")\n",
    "plt.title(\"BMI: Actual vs Predicted Charges\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot for Smoker\n",
    "plt.scatter(X_test_tensor[:, 1].numpy(), y_actual, color='red', label='Actual Charges')\n",
    "plt.scatter(X_test_tensor[:, 1].numpy(), y_pred, color='blue', label='Predicted Charges')\n",
    "plt.xlabel(\"Smoker\")\n",
    "plt.ylabel(\"Charges\")\n",
    "plt.title(\"Smoker: Actual vs Predicted Charges\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot for Regions\n",
    "for region_index in range(3, 7):  # Assuming regions are columns 3 to 6\n",
    "    plt.scatter(X_test_tensor[:, region_index].numpy(), y_actual, color='red', label='Actual Charges')\n",
    "    plt.scatter(X_test_tensor[:, region_index].numpy(), y_pred, color='blue', label='Predicted Charges')\n",
    "    plt.xlabel(f\"Region {region_index - 2}\")\n",
    "    plt.ylabel(\"Charges\")\n",
    "    plt.title(f\"Region {region_index - 2}: Actual vs Predicted Charges\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot for Children\n",
    "plt.scatter(X_test_tensor[:, 4].numpy(), y_actual, color='red', label='Actual Charges')\n",
    "plt.scatter(X_test_tensor[:, 4].numpy(), y_pred, color='blue', label='Predicted Charges')\n",
    "plt.xlabel(\"Children\")\n",
    "plt.ylabel(\"Charges\")\n",
    "plt.title(\"Children: Actual vs Predicted Charges\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ... (previous code)\n",
    "\n",
    "# Calculate Mean Absolute Error\n",
    "mae = mean_absolute_error(y_actual, y_pred)\n",
    "print(f'Mean Absolute Error: {mae:.2f}')\n",
    "\n",
    "# Continue with the rest of the code for scatter plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first attempt at generating a feed forward model. As one can observe my model predicts insurance charges that are approximately thousands of dollars off. Perhaps adding another neural network layer will improve the model's accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fine tuning of Feed-Forward Model\n",
    "Below I added more layers to the model and added training and validation sets. I've added dropout layers and learning rate. I plan to change these hyperparameters to see how they affect the model's MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a dataset named 'data' with features and labels\n",
    "# Features include: age, smoker, bmi, children, region\n",
    "\n",
    "# Example data (replace this with your actual data)\n",
    "data = {\n",
    "    'age': np.random.rand(100, 1),\n",
    "    'smoker': np.random.rand(100, 1),\n",
    "    'bmi': np.random.rand(100, 1),\n",
    "    'children': np.random.rand(100, 1),\n",
    "    'region': np.random.rand(100, 1),\n",
    "    'charges': np.random.rand(100, 1),  # Assuming 'charges' is the target variable\n",
    "}\n",
    "\n",
    "# Combine features into a single input tensor\n",
    "features = np.hstack([data['age'], data['smoker'], data['bmi'], data['children'], data['region']])\n",
    "target = data['charges']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the model architecture\n",
    "class FeedForwardModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, dropout_rate, learning_rate):\n",
    "        super(FeedForwardModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = X_train.shape[1]\n",
    "output_size = 1  # Assuming regression task\n",
    "hidden_size1 = 64\n",
    "hidden_size2 = 32\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.001  # Set your desired learning rate\n",
    "model = FeedForwardModel(input_size, hidden_size1, hidden_size2, output_size, dropout_rate, learning_rate)\n",
    "\n",
    "# Set up the loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    predictions = model(X_train_tensor)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print training information\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    mae_test = mean_absolute_error(y_test_tensor, test_predictions)\n",
    "    print(f\"Mean Absolute Error on Test Set: {mae_test}\")\n",
    "\n",
    "# Visualize results\n",
    "plt.scatter(y_test, test_predictions, color='blue')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', linewidth=2)\n",
    "plt.xlabel('True Charges')\n",
    "plt.ylabel('Predicted Charges')\n",
    "plt.title('True vs Predicted Charges')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
