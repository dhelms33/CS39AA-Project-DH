{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 3\n",
    "\n",
    "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/dereckhelms/cs39aa-project-part-2)\n",
    "\n",
    "Colab link is a work in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creation of Feed-Forward Model\n",
    "Although I do not believe a LTSM model is the most appropriate for this set of structured data, I want to construct one to see how it behaves in relation to another deep learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Desktop\\CS\\CS39AA-Project-DH\\project_part3.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Desktop/CS/CS39AA-Project-DH/project_part3.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Desktop/CS/CS39AA-Project-DH/project_part3.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Desktop/CS/CS39AA-Project-DH/project_part3.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Desktop/CS/CS39AA-Project-DH/project_part3.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Desktop/CS/CS39AA-Project-DH/project_part3.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('insurance.csv')\n",
    "\n",
    "# Extract features and target variable\n",
    "features = df[['age', 'bmi', 'children', 'smoker', 'region']]\n",
    "target = df['charges']\n",
    "\n",
    "# Explicitly create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
    "features = features.copy()\n",
    "\n",
    "# Convert categorical features to one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "features['smoker'] = label_encoder.fit_transform(features['smoker'])\n",
    "features = pd.get_dummies(features, columns=['region'])\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "features[['age', 'bmi', 'children']] = scaler.fit_transform(features[['age', 'bmi', 'children']])\n",
    "\n",
    "# Ensure all data is of numeric type\n",
    "features = features.astype('float32')\n",
    "target = target.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Define the model architecture\n",
    "class InsuranceModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(InsuranceModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # Adjust the number of hidden units as needed\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 1)  # Output is a single number for insurance charge prediction\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create a model instance\n",
    "input_size = X_train_tensor.shape[1]\n",
    "model = InsuranceModel(input_size)\n",
    "\n",
    "# Set up the loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adjust the learning rate as needed\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    predictions = model(X_train_tensor)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print training information\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    test_loss = criterion(test_predictions, y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "\n",
    "# Print some predicted versus actual values\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    sample_indices = np.random.choice(len(X_test_tensor), 5, replace=False)\n",
    "    for i in sample_indices:\n",
    "        prediction = model(X_test_tensor[i])\n",
    "        print(f'Sample {i + 1}: Predicted={prediction.item():.4f}, Actual={y_test_tensor[i].item():.4f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
